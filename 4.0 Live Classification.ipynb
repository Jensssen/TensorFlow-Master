{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package loaded\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Done with loading packages\n",
      "\n",
      "\n",
      "['testimg', 'trainimg', 'use_gray', 'trainlabel', 'imgsize', 'testlabel']\n",
      "\n",
      "\n",
      "752 train images loaded\n",
      "502 test images loaded\n",
      "4096 dimensional input\n",
      "Image size is [64 64]\n",
      "4 classes\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import os,datetime,time , sys\n",
    "print (\"Package loaded\") \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.misc import  imread,imresize\n",
    "import operator\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Done with loading packages\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Load them!\n",
    "cwd = os.getcwd()\n",
    "loadpath = cwd + \"/data/custom_data.npz\"\n",
    "l = np.load(loadpath)\n",
    "\n",
    "# load an image\n",
    "img1 = cv2.imread('Arnold_Schwarzenegger_0003.jpg')\n",
    "img2 = cv2.imread('38.png')\n",
    "img3 = cv2.imread('5.png')\n",
    "img4 = cv2.imread('27.png')\n",
    "img5 = cv2.imread('George_W_Bush_0006.jpg')\n",
    "\n",
    "# See what's in here\n",
    "print (l.files)\n",
    "\n",
    "# Parse data\n",
    "trainimg = l['trainimg']\n",
    "trainlabel = l['trainlabel']\n",
    "testimg = l['testimg']\n",
    "testlabel = l['testlabel']\n",
    "imgsize = l['imgsize']\n",
    "use_gray = l['use_gray']\n",
    "ntrain = trainimg.shape[0]\n",
    "nclass = trainlabel.shape[1]\n",
    "dim    = trainimg.shape[1]\n",
    "ntest  = testimg.shape[0]\n",
    "\n",
    "print(\"\\n\")\n",
    "print (\"%d train images loaded\" % (ntrain))\n",
    "print (\"%d test images loaded\" % (ntest))\n",
    "print (\"%d dimensional input\" % (dim))\n",
    "print (\"Image size is %s\" % (imgsize))\n",
    "print (\"%d classes\" % (nclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK READY\n",
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "#define variables\n",
    "tf.set_random_seed(0)\n",
    "n_input  = dim\n",
    "n_output = nclass\n",
    "if use_gray:\n",
    "    weights  = {\n",
    "        'wc1': tf.Variable(tf.random_normal([5, 5, 1, 128], stddev=0.1),name=\"wc1\"),\n",
    "        'wc2': tf.Variable(tf.random_normal([5, 5, 128, 128], stddev=0.1),name=\"wc2\"),\n",
    "        'wd1': tf.Variable(tf.random_normal(\n",
    "                [(int)(imgsize[0]/4*imgsize[1]/4)*128, 128], stddev=0.1),name=\"wd1\"),\n",
    "        'wd2': tf.Variable(tf.random_normal([128, n_output], stddev=0.1),name=\"wd2\")\n",
    "    }\n",
    "else:\n",
    "    weights  = {\n",
    "        'wc1': tf.Variable(tf.random_normal([5, 5, 3, 128], stddev=0.1),name=\"wc1\"),\n",
    "        'wc2': tf.Variable(tf.random_normal([5, 5, 128, 128], stddev=0.1),name=\"wc2\"),\n",
    "        'wd1': tf.Variable(tf.random_normal(\n",
    "                [(int)(imgsize[0]/4*imgsize[1]/4)*128, 128], stddev=0.1),name=\"wd1\"),\n",
    "        'wd2': tf.Variable(tf.random_normal([128, n_output], stddev=0.1),name=\"wd2\")\n",
    "    }\n",
    "biases   = {\n",
    "    'bc1': tf.Variable(tf.random_normal([128], stddev=0.1),name=\"bc1\"),\n",
    "    'bc2': tf.Variable(tf.random_normal([128], stddev=0.1),name=\"bc2\"),\n",
    "    'bd1': tf.Variable(tf.random_normal([128], stddev=0.1),name=\"bd1\"),\n",
    "    'bd2': tf.Variable(tf.random_normal([n_output], stddev=0.1),name=\"bd2\")\n",
    "}\n",
    "\n",
    "#define network\n",
    "def conv_basic(_input, _w, _b, _keepratio, _use_gray):\n",
    "    # INPUT\n",
    "    if _use_gray:\n",
    "        _input_r = tf.reshape(_input, shape=[-1, imgsize[0], imgsize[1], 1])\n",
    "    else:\n",
    "        _input_r = tf.reshape(_input, shape=[-1, imgsize[0], imgsize[1], 3])\n",
    "    # CONVOLUTION LAYER 1\n",
    "    _conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(_input_r\n",
    "        , _w['wc1'], strides=[1, 1, 1, 1], padding='SAME'), _b['bc1']))\n",
    "    _pool1 = tf.nn.max_pool(_conv1, ksize=[1, 2, 2, 1]\n",
    "        , strides=[1, 2, 2, 1], padding='SAME')\n",
    "    _pool_dr1 = tf.nn.dropout(_pool1, _keepratio)\n",
    "    # CONVOLUTION LAYER 2\n",
    "    _conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(_pool_dr1\n",
    "        , _w['wc2'], strides=[1, 1, 1, 1], padding='SAME'), _b['bc2']))\n",
    "    _pool2 = tf.nn.max_pool(_conv2, ksize=[1, 2, 2, 1]\n",
    "        , strides=[1, 2, 2, 1], padding='SAME')\n",
    "    _pool_dr2 = tf.nn.dropout(_pool2, _keepratio)\n",
    "    # VECTORIZE\n",
    "    _dense1 = tf.reshape(_pool_dr2\n",
    "                         , [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "    # FULLY CONNECTED LAYER 1\n",
    "    _fc1 = tf.nn.relu(tf.add(tf.matmul(_dense1, _w['wd1']), _b['bd1']))\n",
    "    _fc_dr1 = tf.nn.dropout(_fc1, _keepratio)\n",
    "    # FULLY CONNECTED LAYER 2\n",
    "    _out = tf.add(tf.matmul(_fc_dr1, _w['wd2']), _b['bd2'])\n",
    "    # RETURN\n",
    "    out = {\n",
    "        'out': _out\n",
    "    }\n",
    "    return out\n",
    "print (\"NETWORK READY\")\n",
    "\n",
    "#define functions\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_output])\n",
    "keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "# Functions! \n",
    "_pred = conv_basic(X, weights, biases, keepratio, use_gray)['out']\n",
    "_corr = tf.equal(tf.argmax(_pred,1), tf.argmax(Y,1)) # Count corrects\n",
    "accr = tf.reduce_mean(tf.cast(_corr, tf.float32)) # Accuracy\n",
    "init = tf.global_variables_initializer\n",
    "\n",
    "print (\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument <function global_variables_initializer at 0x000001B03CDA8620> has invalid type <class 'function'>, must be a string or Tensor. (Can not convert a function into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 267\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    268\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2583\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2584\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2672\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[1;32m-> 2673\u001b[1;33m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[0;32m   2674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a function into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-733af22c802d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Launch the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m--> 984\u001b[1;33m         self._graph, fetches, feed_dict_string, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \"\"\"\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    269\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    270\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    272\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument <function global_variables_initializer at 0x000001B03CDA8620> has invalid type <class 'function'>, must be a string or Tensor. (Can not convert a function into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "# Capture Video using Webcam\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# Load CascadeClassifier to detect Faces -> frontalface.default.xml file)\n",
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imageCounter=0\n",
    "saveCount=0\n",
    "piclimit = 5\n",
    "faceCaptured=1\n",
    "\n",
    "\n",
    "#Set the Font of the Videotext\n",
    "#font = cv2.InitFont(cv2.CV_FONT_HERSHEY_SIMPLEX, 1, 1, 0, 2, 8) #Creates a font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "#Load weights from saver \n",
    "saver = tf.train.Saver(max_to_keep=3) \n",
    "saver.restore(sess, \"C:/Users/nur20/Documents/GitHub/TensorFlow-Master/save/custom_basic_cnn_idle.ckpt\")\n",
    "print(\"Model restored.\")\n",
    "\n",
    "# Capture Video using Webcam\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# Load CascadeClassifier to detect Faces -> frontalface.default.xml file)\n",
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imageCounter=0\n",
    "saveCount=0\n",
    "piclimit = 5\n",
    "faceCaptured=1\n",
    "\n",
    "\n",
    "#Set the Font of the Videotext\n",
    "#font = cv2.InitFont(cv2.CV_FONT_HERSHEY_SIMPLEX, 1, 1, 0, 2, 8) #Creates a font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"Start restoring.\")\n",
    "\n",
    "#Load weights from saver \n",
    "saver = tf.train.Saver(max_to_keep=3) \n",
    "saver.restore(sess, \"C:/Users/nur20/Documents/GitHub/TensorFlow-Master/save/custom_basic_cnn_idle.ckpt\")\n",
    "print(\"Model restored.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while(imageCounter <200):\n",
    "\t#capture Frame by Frame\n",
    "\tret,frame=cap.read()\n",
    "\n",
    "\t#if (imageCounter <40):\n",
    "\t\t#change the colore of a whole reagon \n",
    "\t#\tframe[200:450, 200:450] =img1 \n",
    "\t\n",
    "\t#if (imageCounter<80 and imageCounter >40):\n",
    "\t#\tframe[200:450, 200:450] = img4\n",
    "\n",
    "\t#if (imageCounter <120 and imageCounter >80):\n",
    "\t#\tframe[200:450, 200:450] = img3\n",
    "\n",
    "\t#if (imageCounter <200 and imageCounter >160):\n",
    "\t#\tframe[200:450, 200:450] = img5\n",
    "\n",
    "\t# convert frame to frame_gray -> Frame loses its colore and gets gray\n",
    "\tframe_gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t#Detect face in the gray frame\n",
    "\tfaces=face_cascade.detectMultiScale(frame_gray)\n",
    "\t#print(\"Facecoordinates: %s\" %faces)\n",
    "\n",
    "\n",
    "\n",
    "\t# defines a list called crop_img \n",
    "\tcrop_img=[None]\n",
    "\n",
    "\t\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "\n",
    "\tfor(x,y,w,h) in faces:\n",
    "\t\tif((w>100)and(h>100)):\n",
    "\t\t\tcv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\t\t\tcrop_img.append(cv2.resize(frame_gray[y:y+h,x:x+w],(64,64)))\n",
    "\t\t\t\n",
    "\n",
    "\t\n",
    "\t#img_gray  = cv2.imread(imageName,0) #load grayscale\n",
    "\t#img_gray= rgb2gray(imread(imageName))\n",
    "\timg_gray_resize=imresize(frame_gray, [64, 64])/255. #resize image to [64x64]\n",
    "\timg_grayvec   = np.reshape(img_gray_resize, (1, -1)) #reshape matrix to vector\n",
    "\t#cv2.imshow(\"bla\",img_gray_resize)\n",
    "\t#cv2.waitKey(1000)\n",
    "\t#print img_grayvec\n",
    "\t#print img_grayvec.shape\n",
    "\timageCounter +=1\n",
    "\t#print(imageCounter)\n",
    "\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tpredictiton=sess.run(tf.nn.softmax(_pred), feed_dict={X: img_grayvec,keepratio:1.}) #make prediction\n",
    "\tprint (predictiton)\n",
    "\t\n",
    "\tindex, value = max(enumerate(predictiton[0]), key=operator.itemgetter(1)) #find highest value in output vector\n",
    "\t\n",
    "\tclassName=\"\"\n",
    "\tif index==0:\n",
    "\t  className=\"Tyler\"\n",
    "\telif index ==1:\n",
    "\t  className=\"Rai\"\n",
    "\telif index ==2:\n",
    "\t  className=\"Bush\"\n",
    "\telif index ==3:\n",
    "\t  className=\"Vladimir\"\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "\tprint (\"Prediciton is class '%s' with accuracy %0.3f\"%(className,value))\n",
    "\n",
    "\tif index ==0:\n",
    "\t\tcv.PutText(cv.fromarray(frame),className, (x,y-8),font, 255) #Draw the text\n",
    "\telif index == 1:\n",
    "\t\tcv.PutText(cv.fromarray(frame),className, (x,y-8),font, 255) #Draw the text\t\t\n",
    "\telif index == 2:\n",
    "\t\tcv.PutText(cv.fromarray(frame),className, (x,y-8),font, 255) #Draw the text\t\t\n",
    "\telif index == 3:\n",
    "\t\tcv.PutText(cv.fromarray(frame),className, (x,y-8),font, 255) #Draw the text\t\t\n",
    "\telif index == 4:\n",
    "\t\tcv.PutText(cv.fromarray(frame),className, (x,y-8),font, 255) #Draw the text\t\t\n",
    "\telif index == 5:\n",
    "\t\tcv.PutText(cv.fromarray(frame),className, (x,y-8),font, 255) #Draw the text\t\t\n",
    "\n",
    "\n",
    "\n",
    "\tcv2.imshow('frame',frame)\n",
    "\n",
    "\tcv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sess.close()\n",
    "print (\"Session closed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
