{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded\n",
      "['testimg', 'trainimg', 'use_gray', 'trainlabel', 'imgsize', 'testlabel']\n",
      "752 train images loaded\n",
      "502 test images loaded\n",
      "4096 dimensional input\n",
      "Image size is [64 64]\n",
      "4 classes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import sys\n",
    "import cv2\n",
    "from scipy.misc import  imread,imresize\n",
    "import operator\n",
    "\n",
    "print(\"Packages loaded\")\n",
    "\n",
    "# Load datasets from npz file\n",
    "cwd = os.getcwd()\n",
    "loadpath = cwd + \"/data/custom_data.npz\"\n",
    "l = np.load(loadpath)\n",
    "\n",
    "# See what's inside of the npz file\n",
    "print(l.files)\n",
    "\n",
    "# Parse data\n",
    "trainimg = l['trainimg']\n",
    "trainlabel = l['trainlabel']\n",
    "testimg = l['testimg']\n",
    "testlabel = l['testlabel']\n",
    "imgsize = l['imgsize']\n",
    "use_gray = l['use_gray']\n",
    "\n",
    "# ntrain contains the number of images in the trainingset (trainimg.shape ->[553 x 4096])\n",
    "ntrain = trainimg.shape[0]\n",
    "# dim contains the number of pixels of an image\n",
    "dim = trainimg.shape[1]\n",
    "# ntest contains the number of images in the testset (testimg.shape ->[370 x 4096])\n",
    "ntest = testimg.shape[0]\n",
    "# nclass contains the number of labels (trainlabel.shape ->[553 x 2])\n",
    "nclass = trainlabel.shape[1] # \n",
    "\n",
    "print(\"%d train images loaded\" % (ntrain))\n",
    "print(\"%d test images loaded\" % (ntest))\n",
    "print(\"%d dimensional input\" % (dim))\n",
    "print(\"Image size is %s\" % (imgsize))\n",
    "print(\"%d classes\" % (nclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK READY\n",
      "FUNCTIONS READY\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "start restoring.\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/nur20/Documents/GitHub/TensorFlow-Master/save/custom_basic_cnn_idle.ckpt\n",
      "Model restored.\n",
      "(1, 4096)\n",
      "[[  9.89172339e-01   6.70049167e-06   1.06630739e-06   1.08198598e-02]]\n",
      "Prediciton is class 'al gore' with accuracy 0.989\n",
      " Test accuracy: 0.131\n",
      "Session closed.\n"
     ]
    }
   ],
   "source": [
    "#define variables\n",
    "tf.set_random_seed(0)\n",
    "n_input = dim\n",
    "n_output = nclass\n",
    "if use_gray:\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.random_normal([5, 5, 1, 128], stddev=0.1), name=\"wc1\"),\n",
    "        'wc2': tf.Variable(tf.random_normal([5, 5, 128, 128], stddev=0.1), name=\"wc2\"),\n",
    "        'wd1': tf.Variable(tf.random_normal(\n",
    "            [(int)(imgsize[0]/4*imgsize[1]/4)*128, 128], stddev=0.1), name=\"wd1\"),\n",
    "        'wd2': tf.Variable(tf.random_normal([128, n_output], stddev=0.1), name=\"wd2\")\n",
    "    }\n",
    "else:\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.random_normal([5, 5, 3, 128], stddev=0.1), name=\"wc1\"),\n",
    "        'wc2': tf.Variable(tf.random_normal([5, 5, 128, 128], stddev=0.1), name=\"wc2\"),\n",
    "        'wd1': tf.Variable(tf.random_normal(\n",
    "            [(int)(imgsize[0] / 4 * imgsize[1] / 4) * 128, 128], stddev=0.1), name=\"wd1\"),\n",
    "        'wd2': tf.Variable(tf.random_normal([128, n_output], stddev=0.1), name=\"wd2\")\n",
    "    }\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([128], stddev=0.1), name=\"bc1\"),\n",
    "    'bc2': tf.Variable(tf.random_normal([128], stddev=0.1), name=\"bc2\"),\n",
    "    'bd1': tf.Variable(tf.random_normal([128], stddev=0.1), name=\"bd1\"),\n",
    "    'bd2': tf.Variable(tf.random_normal([n_output], stddev=0.1), name=\"bd2\")\n",
    "}\n",
    "\n",
    "#define network\n",
    "def conv_basic(_input, _w, _b, _keepratio, _use_gray):\n",
    "    # INPUT\n",
    "    if _use_gray:\n",
    "        _input_r = tf.reshape(_input, shape=[-1, imgsize[0], imgsize[1], 1])\n",
    "    else:\n",
    "        _input_r = tf.reshape(_input, shape=[-1, imgsize[0], imgsize[1], 3])\n",
    "    # CONVOLUTION LAYER 1\n",
    "    _conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(_input_r\n",
    "      , _w['wc1'], strides=[1, 1, 1, 1], padding='SAME'), _b['bc1']))\n",
    "    _pool1 = tf.nn.max_pool(_conv1, ksize=[1, 2, 2, 1]\n",
    "                            , strides=[1, 2, 2, 1], padding='SAME')\n",
    "    _pool_dr1 = tf.nn.dropout(_pool1, _keepratio)\n",
    "    # CONVOLUTION LAYER 2\n",
    "    _conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(_pool_dr1\n",
    "                                                    , _w['wc2'], strides=[1, 1, 1, 1], padding='SAME'), _b['bc2']))\n",
    "    _pool2 = tf.nn.max_pool(_conv2, ksize=[1, 2, 2, 1]\n",
    "                            , strides=[1, 2, 2, 1], padding='SAME')\n",
    "    _pool_dr2 = tf.nn.dropout(_pool2, _keepratio)\n",
    "    # VECTORIZE\n",
    "    _dense1 = tf.reshape(_pool_dr2\n",
    "                         , [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "    # FULLY CONNECTED LAYER 1\n",
    "    _fc1 = tf.nn.relu(tf.add(tf.matmul(_dense1, _w['wd1']), _b['bd1']))\n",
    "    _fc_dr1 = tf.nn.dropout(_fc1, _keepratio)\n",
    "    # FULLY CONNECTED LAYER 2\n",
    "    _out = tf.add(tf.matmul(_fc_dr1, _w['wd2']), _b['bd2'])\n",
    "    # RETURN\n",
    "    out = {\n",
    "        'out': _out\n",
    "    }\n",
    "    return out\n",
    "print (\"NETWORK READY\")\n",
    "\n",
    "#define functions\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "# Functions! \n",
    "_pred = conv_basic(x, weights, biases, keepratio, use_gray)['out']\n",
    "_corr = tf.equal(tf.argmax(_pred,1), tf.argmax(y,1)) # Count corrects\n",
    "accr = tf.reduce_mean(tf.cast(_corr, tf.float32)) # Accuracy\n",
    "print (\"FUNCTIONS READY\")\n",
    "\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(\"start restoring.\")\n",
    "\n",
    "\n",
    "#Load weights from saver \n",
    "saver = tf.train.Saver(max_to_keep=3) \n",
    "saver.restore(sess, \"C:/Users/nur20/Documents/GitHub/TensorFlow-Master/save/custom_basic_cnn_idle.ckpt\")\n",
    "print(\"Model restored.\")\n",
    "\n",
    "imageName=\"C:/Users/nur20/Documents/GitHub/TensorFlow-Master/img_dataset/George_W_Bush/George_W_Bush_0001.jpg\"\n",
    "\n",
    "#imageName=\"/home/soeren/data/Facerecognition/img_dataset/Arnold_Schwarzenegger/Arnold_Schwarzenegger_0040.jpg\"\n",
    "#imageName=\"/home/soeren/data/Facerecognition/img_dataset/Vladimir_Putin/Vladimir_Putin_0032.jpg\"\n",
    "#imageName=\"/home/soeren/data/Facerecognition/img_dataset/Junichiro_Koizumi/Junichiro_Koizumi_0014.jpg\"\n",
    "#imageName=\"/home/soeren/data/Facerecognition/img_dataset/George_W_Bush/George_W_Bush_0031.jpg\"\n",
    "#imageName=\"/home/soeren/data/Facerecognition/img_dataset/Soeren_Erichsen/6.png\"\n",
    "#imageName=\"/home/soeren/data/Facerecognition/img_dataset/Pascal/7.png\"\n",
    "#imageName=\"/home/soeren/data/Facerecognition/img_dataset/Apple/7.png\"\n",
    "\n",
    "\n",
    "img_gray  = cv2.imread(imageName,0) #load grayscale\n",
    "#img_gray= rgb2gray(imread(imageName))\n",
    "img_gray_resize=imresize(img_gray, [64, 64])/255. #resize image to [64x64]\n",
    "img_grayvec   = np.reshape(img_gray_resize, (1, -1)) #reshape matrix to vector\n",
    "#cv2.imshow(\"bla\",img_gray_resize)\n",
    "#cv2.waitKey(1000)\n",
    "#print img_grayvec\n",
    "print (img_grayvec.shape)\n",
    "\n",
    "\n",
    "predictiton=sess.run(tf.nn.softmax(_pred), feed_dict={x: img_grayvec,keepratio:1.}) #make prediction\n",
    "print (predictiton)\n",
    "\n",
    "index, value = max(enumerate(predictiton[0]), key=operator.itemgetter(1)) #find highest value in output vector\n",
    "\n",
    "className=\"\"\n",
    "if index==0:\n",
    "  className=\"al gore\"\n",
    "elif index ==1:\n",
    "  className=\"Bush\"\n",
    "elif index ==2:\n",
    "  className=\"tyler\"\n",
    "elif index ==3:\n",
    "  className=\"jobs\"\n",
    "\n",
    "\n",
    "print (\"Prediciton is class '%s' with accuracy %0.3f\"%(className,value))\n",
    "\n",
    "# Do some work with the model\n",
    "test_acc = sess.run(accr, feed_dict={x: testimg, y: testlabel, keepratio:1.})\n",
    "    \n",
    "print (\" Test accuracy: %.3f\" % (test_acc))\n",
    "\n",
    "\n",
    "sess.close()\n",
    "print (\"Session closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
